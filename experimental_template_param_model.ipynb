{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Explanation\n",
    "\n",
    "This is typical DCNN model for training vent-hole data's output prediction.\n",
    "\n",
    "1. `drag`: Drag\n",
    "2. `avg_temp`: Average temperature\n",
    "3. `max_temp`: Maximum temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prediction.cnn.data_transformer import BinaryImageTransformer\n",
    "\n",
    "transformer = BinaryImageTransformer(\n",
    "    data_dir=\"model/data\", grid_width=100, grid_resolution=2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = transformer.generate_images()\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(images_matrix) -> None:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for idx, image_matrix in enumerate(images_matrix[0:10]):\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(\n",
    "            image_matrix,\n",
    "            cmap=\"gray\",\n",
    "            # interpolation=\"nearest\",\n",
    "        )  # Display the image using a grayscale colormap\n",
    "        plt.title(f\"Data : {idx+1}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# plot_img(image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from typing import Callable, Union, Literal, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Configs and Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Setup configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration: Use GPU if available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data path\n",
    "IMAGE_MATRIX_PATH = transformer.image_matrix_path\n",
    "OUTPUT_MATRIX_PATH = transformer.output_matrix_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Target\n",
    "TRAIN_TARGET: Literal[\"drag\", \"avg_temp\", \"max_temp\"] = \"drag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MINI_BATCH_SIZE = 50\n",
    "TRAIN_RATIO = 0.75\n",
    "NUM_EPOCHS = 100\n",
    "EARLY_STOP_CNT = 10  # inf can be used to disable early stopping e.g) float('inf')\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "ACTIVATE_L2_REGULARIZATION = True\n",
    "WEIGHT_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Define data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(\n",
    "    numpy_tensor_path: str, train_ratio: float, data_type: Literal[\"image\", \"tensor\"]\n",
    ") -> dict[Literal[\"train\", \"test\"], torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Loads data from a .npy file, splits it into training and testing sets,\n",
    "    and converts them to PyTorch tensors.\n",
    "\n",
    "    Args:\n",
    "        numpy_tensor_path (str): Path to the .npy file.\n",
    "        train_ratio (float): Proportion of data to use for training.\n",
    "        data_type (Literal[\"image\", \"tensor\"]): Type of data (\"image\" or \"tensor\").\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing 'train' and 'test' tensors.\n",
    "    \"\"\"\n",
    "    # Load .npy data\n",
    "    data = np.load(\n",
    "        numpy_tensor_path\n",
    "    )  # Assuming shape is (batch_size, height, width) or (batch_size, features)\n",
    "    data_len = len(data)\n",
    "    split_index = int(data_len * train_ratio)\n",
    "\n",
    "    # Split data into training and testing\n",
    "    train_set = data[:split_index]\n",
    "    test_set = data[split_index:]\n",
    "\n",
    "    # Convert NumPy arrays to PyTorch tensors\n",
    "    train_tensor = torch.from_numpy(train_set).float()\n",
    "    test_tensor = torch.from_numpy(test_set).float()\n",
    "\n",
    "    if data_type == \"image\":\n",
    "        # Add channel dimension for grayscale images: (batch_size, 1, N, N)\n",
    "        train_tensor = train_tensor.unsqueeze(1)\n",
    "        test_tensor = test_tensor.unsqueeze(1)\n",
    "\n",
    "    return {\"train\": train_tensor, \"test\": test_tensor}\n",
    "\n",
    "\n",
    "class PhysicsImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading physics-related images and their corresponding targets.\n",
    "    Applies data augmentation (horizontal flip) to the images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_tensor: torch.Tensor,\n",
    "        output_tensor: torch.Tensor,\n",
    "        augment: bool = False,\n",
    "        image_tensor_transformer: Union[\n",
    "            Callable[[torch.Tensor], torch.Tensor], None\n",
    "        ] = None,\n",
    "        output_tensor_transformer: Union[\n",
    "            Callable[[torch.Tensor], torch.Tensor], None\n",
    "        ] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_tensor (torch.Tensor): Tensor of images with shape (num_samples, 1, N, N).\n",
    "            output_tensor (torch.Tensor): Tensor of targets with shape (num_samples, 3).\n",
    "            augment (bool, optional): Whether to apply data augmentation. Defaults to False.\n",
    "            image_tensor_transformer (Union[Callable[[torch.Tensor], torch.Tensor], None], optional): Transformation function for the image tensor. Defaults to None.\n",
    "            output_tensor_transformer (Union[Callable[[torch.Tensor], torch.Tensor], None], optional): Transformation function for the output tensor. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.image_tensor = (\n",
    "            image_tensor\n",
    "            if image_tensor_transformer is None\n",
    "            else image_tensor_transformer(image_tensor)\n",
    "        )\n",
    "        self.output_tensor = (\n",
    "            output_tensor\n",
    "            if output_tensor_transformer is None\n",
    "            else output_tensor_transformer(output_tensor)\n",
    "        )\n",
    "        self.augment = augment\n",
    "        self.origin_data_size = len(image_tensor)\n",
    "        self.transform = (\n",
    "            transforms.Compose(\n",
    "                [transforms.RandomVerticalFlip(p=1.0)]  # Always flip when augmenting\n",
    "            )\n",
    "            if self.augment\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        # If augmenting, double the dataset size\n",
    "        return self.origin_data_size * 2 if self.augment else self.origin_data_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.augment and idx >= self.origin_data_size:\n",
    "            # Augmented sample: flip the image horizontally\n",
    "            original_idx = idx - self.origin_data_size\n",
    "            image = self.image_tensor[original_idx]\n",
    "            image = self.transform(image)\n",
    "            target = self.output_tensor[original_idx]\n",
    "        else:\n",
    "            # Original sample\n",
    "            image = self.image_tensor[idx]\n",
    "            target = self.output_tensor[idx]\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Data loading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the data paths exist\n",
    "if not os.path.exists(IMAGE_MATRIX_PATH):\n",
    "    raise FileNotFoundError(f\"Image data file not found at {IMAGE_MATRIX_PATH}\")\n",
    "if not os.path.exists(OUTPUT_MATRIX_PATH):\n",
    "    raise FileNotFoundError(f\"Output data file not found at {OUTPUT_MATRIX_PATH}\")\n",
    "\n",
    "\n",
    "def ExtractOutputProperty(\n",
    "    output_tensor: torch.Tensor, property: Literal[\"drag\", \"avg_temp\", \"max_temp\"]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extracts a specific property from the output tensor.\n",
    "\n",
    "    Args:\n",
    "        output_tensor (torch.Tensor): Output tensor with shape (num_samples, num_properties).\n",
    "        property (Literal[\"drag\", \"avg_temp\", \"max_temp\"]): Property to extract.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor containing the specified property.\n",
    "    \"\"\"\n",
    "    property_map = {\"drag\": 0, \"avg_temp\": 1, \"max_temp\": 2}\n",
    "    return output_tensor[:, property_map[property]]\n",
    "\n",
    "\n",
    "# Load image and output data\n",
    "image_data = get_data_set(\n",
    "    numpy_tensor_path=IMAGE_MATRIX_PATH,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    data_type=\"image\",\n",
    ")\n",
    "output_data = get_data_set(\n",
    "    numpy_tensor_path=OUTPUT_MATRIX_PATH,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    data_type=\"tensor\",\n",
    ")\n",
    "\n",
    "\n",
    "# Create training and testing datasets\n",
    "# Apply data augmentation (flipping) only to the training dataset\n",
    "train_dataset = PhysicsImageDataset(\n",
    "    image_tensor=image_data[\"train\"],\n",
    "    output_tensor=output_data[\"train\"],\n",
    "    augment=True,  # Enable augmentation for training\n",
    "    output_tensor_transformer=lambda x: ExtractOutputProperty(x, TRAIN_TARGET),\n",
    ")\n",
    "test_dataset = PhysicsImageDataset(\n",
    "    image_tensor=image_data[\"test\"],\n",
    "    output_tensor=output_data[\"test\"],\n",
    "    augment=True,  # No augmentation for testing\n",
    "    output_tensor_transformer=lambda x: ExtractOutputProperty(x, TRAIN_TARGET),\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=MINI_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=MINI_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming train_loader is your DataLoader\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Access a single batch\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(\"Input batch shape:\", inputs.shape)\n",
    "print(\"Target batch shape:\", targets.shape)\n",
    "\n",
    "# If you want to print the first few elements (just for understanding):\n",
    "print(\"First 5 inputs:\\n\", inputs[:5])\n",
    "print(\"First 5 targets:\\n\", targets[:5])\n",
    "\n",
    "\n",
    "# Assuming inputs are images in the shape [batch_size, channels, height, width]\n",
    "# For example, a batch of grayscale images would have the shape [batch_size, 1, height, width]\n",
    "# For RGB images, the shape would be [batch_size, 3, height, width]\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(inputs[i][0], cmap=\"gray\")  # Display the first channel of the image\n",
    "    plt.title(f\"Label: {targets[i].item()}\")\n",
    "    plt.show()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(inputs[i][0], cmap=\"gray\")  # Display the first channel of the image\n",
    "    plt.title(f\"Label: {targets[i].item()}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def define_model_name(self, model_name: str) -> None:\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Formula :: NewImageSize = (PrevImageSize - KernelSize + 2PaddingSize) / Stride + 1\n",
    "\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            # @Layer1 = 1x200x200 -> 32x200x200\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            # @Layer3 = 32x200x200 -> 64x200x200\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # @Layer4 = 64x200x200 -> 64x100x100\n",
    "        )\n",
    "\n",
    "        self.conv_layer_3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=1),\n",
    "            # @Layer5 = 64x100x100 -> 128x48x48\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv_layer_4 = nn.Sequential(\n",
    "            # NewImageSize = (48 - 3 + 2*1) / 1 + 1 = 48\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            # @Layer7 = 128x48x48 -> 256x48x48\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # @Layer8 = 256x48x48 -> 256x24x24\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(256 * 24 * 24, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.conv_layer_3(x)\n",
    "        x = self.conv_layer_4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "import sys\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def capture_print_output(func, *args, **kwargs):\n",
    "    # Create a string IO stream to capture the output\n",
    "    captured_output = io.StringIO()\n",
    "\n",
    "    # Redirect stdout to the StringIO object\n",
    "    sys.stdout = captured_output\n",
    "\n",
    "    # Execute the function\n",
    "    func(*args, **kwargs)\n",
    "\n",
    "    # Reset stdout to default\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "    # Get the output from the StringIO object\n",
    "    output_value = captured_output.getvalue()\n",
    "\n",
    "    # Close the StringIO stream\n",
    "    captured_output.close()\n",
    "\n",
    "    # Return the captured output\n",
    "    return output_value\n",
    "\n",
    "\n",
    "def generate_uuid_from_seed(seed_str: str) -> uuid.UUID:\n",
    "    # Create an MD5 hash from the seed string\n",
    "    hash_object = hashlib.md5(seed_str.encode())\n",
    "\n",
    "    # Use the hash to create a UUID\n",
    "    return uuid.UUID(hash_object.hexdigest())\n",
    "\n",
    "\n",
    "def create_model_save_storage(\n",
    "    model_name: str, model_architecture: str, hyperparameter_dict: dict[str, any]\n",
    ") -> Tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    Create a dir for model experiment and record the model configuration.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model\n",
    "        model_architecture (str): Architecture of the model\n",
    "        hyperparameter_dict (dict[str, any]): Dictionary of hyperparameters\n",
    "\n",
    "    Returns:\n",
    "        str: model save directory path\n",
    "    \"\"\"\n",
    "    # Create a directory to store the model and its explanation\n",
    "    model_uuid = generate_uuid_from_seed(model_architecture)\n",
    "    model_dir = f\"model/param/models/{TRAIN_TARGET}/{model_name}_{model_uuid}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    hyperparameter_description_str = \"\\n\".join(\n",
    "        [f\"> {key} : {value}\" for key, value in hyperparameter_dict.items()]\n",
    "    )\n",
    "\n",
    "    model_config_path = f\"{model_dir}/config.txt\"\n",
    "    model_weight_path = f\"{model_dir}/model.pth\"\n",
    "\n",
    "    # Save the model explanation to a text file\n",
    "    with open(f\"{model_dir}/config.txt\", \"w\") as f:\n",
    "        f.write(f\"\\n{\"-\" * 100}\\n\")\n",
    "        f.write(f\"Generated at : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(model_name)\n",
    "        f.write(f\"\\n{\"-\" * 100}\\n\")\n",
    "        f.write(\"Hyperparameters\\n\")\n",
    "        f.write(hyperparameter_description_str)\n",
    "        f.write(f\"\\n{\"-\" * 100}\\n\")\n",
    "        f.write(\"Model Architecture\\n\")\n",
    "        f.write(model_architecture)\n",
    "\n",
    "    return model_dir, model_config_path, model_weight_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Loss function, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Loss\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = RMSELoss()\n",
    "\n",
    "optimizer = (\n",
    "    optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    if ACTIVATE_L2_REGULARIZATION\n",
    "    else optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6(Optional). Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "STEP_SIZE = NUM_EPOCHS / 10\n",
    "# Use a learning rate scheduler that reduces LR by a factor of 0.1 every 10 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Initialize model storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Define the model name and save storage\n",
    "model_name = \"MODEL_NAME\"\n",
    "\n",
    "if model_name == \"MODEL_NAME\":\n",
    "    raise ValueError(\"Please define a model name before running the model.\")\n",
    "\n",
    "model.define_model_name(model_name)\n",
    "\n",
    "# Temporary move model to CPU for summary\n",
    "model_details = capture_print_output(\n",
    "    summary, model.to(\"cpu\"), input_size=(1, 200, 200), device=\"cpu\"\n",
    ")\n",
    "\n",
    "# Back to original device, MPS\n",
    "# Note, -1 = <batch size> is not fixed.\n",
    "model.to(device)\n",
    "\n",
    "# Create model save storage for experiment\n",
    "model_save_path, model_config_path, model_weight_path = create_model_save_storage(\n",
    "    model_name=model.model_name,\n",
    "    model_architecture=model_details,\n",
    "    hyperparameter_dict={\n",
    "        \"MINI_BATCH_SIZE\": MINI_BATCH_SIZE,\n",
    "        \"TRAIN_RATIO\": TRAIN_RATIO,\n",
    "        \"NUM_EPOCHS\": NUM_EPOCHS,\n",
    "        \"EARLY_STOP_CNT\": EARLY_STOP_CNT,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE,\n",
    "        \"WEIGHT_DECAY\": WEIGHT_DECAY,\n",
    "        \"LOSS_FUNCTION\": loss_function.__str__(),\n",
    "        \"OPTIMIZER\": optimizer.__str__(),\n",
    "        \"SCHEDULER\": scheduler.__str__(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_training_result(\n",
    "    epoch_end: int,\n",
    "    train_loss_record: list[float],\n",
    "    val_loss_record: list[float],\n",
    "):\n",
    "    # Save the training result to a text file\n",
    "    with open(f\"{model_save_path}/training_result.json\", \"w\") as f:\n",
    "        f.write(\n",
    "            f'{{\"epoch_end\": {epoch_end}, \"train_loss\": {train_loss_record}, \"val_loss\": {val_loss_record}}}'\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_loss_curve(\n",
    "    epoch_end: int, train_loss_record: list[float], val_loss_record: list[float]\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "    epoch_end_linspace = np.linspace(0, epoch_end, len(train_loss_record))\n",
    "    plt.plot(\n",
    "        epoch_end_linspace,\n",
    "        train_loss_record,\n",
    "        label=\"Train Loss\",\n",
    "        color=\"blue\",\n",
    "        linestyle=\"-\",\n",
    "        marker=\"o\",\n",
    "        markersize=3,\n",
    "    )\n",
    "    val_linspace = np.linspace(0, epoch_end, len(val_loss_record))\n",
    "    plt.plot(\n",
    "        val_linspace,\n",
    "        val_loss_record,\n",
    "        label=\"Val Loss\",\n",
    "        color=\"orange\",\n",
    "        linestyle=\"-\",\n",
    "        marker=\">\",\n",
    "        markersize=3,\n",
    "    )\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Cost Curve (Epochs: {epoch_end}) for model {model_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def record_experimental_result(\n",
    "    result_analysis: str,\n",
    ") -> None:\n",
    "    if result_analysis == \"\":\n",
    "        raise ValueError(\n",
    "            \"Please provide a result analysis to record. You should write a markdown string.\"\n",
    "        )\n",
    "\n",
    "    with open(f\"{model_save_path}/result_analysis.md\", \"w\") as f:\n",
    "        f.write(\"# Model Result Analysis\\n\")\n",
    "        f.write(f\"recorded at : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(result_analysis)\n",
    "        f.write(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_epoch(\n",
    "    epoch: int,\n",
    "    learning_rate: float,\n",
    "    epoch_train_loss,\n",
    "    epoch_val_loss,\n",
    "):\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{NUM_EPOCHS} | Learning Rate: {learning_rate:.4f} | Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer,\n",
    "    loss_function,\n",
    "    epoch_count: int,\n",
    "    early_stop_cnt: int,\n",
    "    learning_scheduler: Union[lr_scheduler.StepLR, None] = None,\n",
    ") -> Tuple[int, list[float], list[float]]:\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    train_loss_record = []\n",
    "    val_loss_record = []\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            # Move to GPU\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            predict = model(inputs)\n",
    "            predict = predict.squeeze(1)\n",
    "\n",
    "            # Compute loss\n",
    "            val_loss = loss_function(predict, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            val_loss.backward()\n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "            # Learning rate scheduler if available\n",
    "            if learning_scheduler is not None:\n",
    "                learning_scheduler.step()\n",
    "\n",
    "            # Record the loss\n",
    "            train_loss = val_loss.item()\n",
    "            train_loss_record.append(train_loss)\n",
    "\n",
    "            running_train_loss += train_loss * inputs.size(0)  # Accumulate loss\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Freeze the model\n",
    "        running_val_loss = 0.0\n",
    "        val_outputs = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                predict = model(inputs)\n",
    "                predict = predict.squeeze(1)\n",
    "\n",
    "                val_loss = loss_function(predict, targets)\n",
    "                val_loss_record.append(val_loss.item())\n",
    "\n",
    "                running_val_loss += val_loss.item() * inputs.size(0)\n",
    "\n",
    "                val_outputs.append(predict.cpu().numpy())\n",
    "                val_targets.append(targets.cpu().numpy())\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(test_loader.dataset)\n",
    "\n",
    "        # Report the metrics\n",
    "        report_epoch(\n",
    "            epoch,\n",
    "            learning_rate=optimizer.param_groups[0][\"lr\"],\n",
    "            epoch_train_loss=epoch_train_loss,\n",
    "            epoch_val_loss=epoch_val_loss,\n",
    "        )\n",
    "\n",
    "        # Early stopping Check\n",
    "        is_new_best = epoch_val_loss < best_val_loss\n",
    "        if is_new_best:\n",
    "            print(\n",
    "                f\"> New best model found, prev: {best_val_loss:.4f} -> new: {epoch_val_loss:.4f}\"\n",
    "            )\n",
    "            best_val_loss = epoch_val_loss\n",
    "            early_stopping_counter = 0\n",
    "            torch.save(model.state_dict(), model_weight_path)\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            should_stop = early_stopping_counter >= early_stop_cnt\n",
    "            if should_stop:\n",
    "                print(\"Early stopping triggered.\")\n",
    "\n",
    "                return epoch, train_loss_record, val_loss_record\n",
    "\n",
    "    return epoch, train_loss_record, val_loss_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch, train_loss_record, val_loss_record = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    epoch_count=NUM_EPOCHS,\n",
    "    early_stop_cnt=EARLY_STOP_CNT,\n",
    "    learning_scheduler=scheduler,  # None if not using scheduler or just remove the argument\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Save model analyze experimental results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curve(final_epoch, train_loss_record, val_loss_record)\n",
    "\n",
    "save_model_training_result(final_epoch, train_loss_record, val_loss_record)\n",
    "\n",
    "# Record the result analysis\n",
    "result_analysis = \"\"\"\"\"\"\n",
    "\n",
    "record_experimental_result(result_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluation(Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(model) -> None:\n",
    "    model.load_state_dict(torch.load(model_weight_path))\n",
    "    model.eval()\n",
    "    print(\"Loaded the best model based on validation loss.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Inference by test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_validation(model: Model) -> None:\n",
    "    running_val_loss = 0.0\n",
    "    val_outputs = []\n",
    "    val_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            predict = model(inputs)\n",
    "            predict = predict.squeeze(1)\n",
    "\n",
    "            val_loss = loss_function(predict, targets)\n",
    "\n",
    "            running_val_loss += val_loss.item() * inputs.size(0)\n",
    "\n",
    "            val_outputs.append(predict.cpu().numpy())\n",
    "            val_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    final_val_loss = running_val_loss / len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Final Validation Loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "load_best_model(model)\n",
    "\n",
    "final_validation(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
